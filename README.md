# sathealth
Bayesian optimization can be directly applied by: python bayes_optimize.py if needed data and trained model are under the same directory.
Please notice that autogluon requires python version to be 3.12 so that program will break if yours doesn't meet the demand. However, the difference may not lead to fatal problems. You can make subtle changes to ignore the warning, which helps the program run successfully.

# requirements
pip:
      - absl-py==2.2.2
      - accelerate==0.34.2
      - adagio==0.2.6
      - aiohappyeyeballs==2.6.1
      - aiohttp==3.11.16
      - aiohttp-cors==0.8.1
      - aiosignal==1.3.2
      - alembic==1.15.2
      - annotated-types==0.7.0
      - antlr4-python3-runtime==4.9.3
      - appdirs==1.4.4
      - attrs==25.3.0
      - autogluon==1.2
      - autogluon-common==1.2
      - autogluon-core==1.2
      - autogluon-features==1.2
      - autogluon-multimodal==1.2
      - autogluon-tabular==1.2
      - autogluon-timeseries==1.2
      - beautifulsoup4==4.13.4
      - blis==0.7.11
      - boto3==1.37.37
      - botocore==1.37.37
      - cachetools==5.5.2
      - catalogue==2.0.10
      - catboost==1.2.8
      - certifi==2025.1.31
      - charset-normalizer==3.4.1
      - click==8.1.8
      - cloudpathlib==0.21.0
      - cloudpickle==3.1.1
      - colorama==0.4.6
      - colorful==0.5.6
      - colorlog==6.9.0
      - confection==0.1.5
      - contourpy==1.3.2
      - coreforecast==0.0.12
      - cycler==0.12.1
      - cymem==2.0.11
      - datasets==3.5.0
      - defusedxml==0.7.1
      - dill==0.3.8
      - distlib==0.3.9
      - einops==0.8.1
      - et-xmlfile==2.0.0
      - evaluate==0.4.3
      - fastai==2.7.19
      - fastcore==1.7.29
      - fastdownload==0.0.7
      - fastprogress==1.0.3
      - filelock==3.18.0
      - fonttools==4.57.0
      - frozenlist==1.6.0
      - fs==2.4.16
      - fsspec==2024.12.0
      - fugue==0.9.1
      - future==1.0.0
      - gdown==5.2.0
      - gluonts==0.16.1
      - google-api-core==2.24.2
      - google-auth==2.39.0
      - googleapis-common-protos==1.70.0
      - graphviz==0.20.3
      - greenlet==3.2.0
      - grpcio==1.71.0
      - huggingface-hub==0.30.2
      - hyperopt==0.2.7
      - idna==3.10
      - imageio==2.37.0
      - jinja2==3.1.6
      - jmespath==1.0.1
      - joblib==1.4.2
      - jsonschema==4.21.1
      - jsonschema-specifications==2024.10.1
      - kiwisolver==1.4.8
      - langcodes==3.5.0
      - language-data==1.3.0
      - lazy-loader==0.4
      - lightgbm==4.5.0
      - lightning==2.5.1
      - lightning-utilities==0.14.3
      - linkify-it-py==2.0.3
      - llvmlite==0.44.0
      - mako==1.3.10
      - marisa-trie==1.2.1
      - markdown==3.8
      - markdown-it-py==3.0.0
      - markupsafe==3.0.2
      - matplotlib==3.10.1
      - mdit-py-plugins==0.4.2
      - mdurl==0.1.2
      - memray==1.17.1
      - mlforecast==0.13.4
      - model-index==0.1.11
      - mpmath==1.3.0
      - msgpack==1.1.0
      - multidict==6.4.3
      - multiprocess==0.70.16
      - murmurhash==1.0.12
      - narwhals==1.35.0
      - networkx==3.4.2
      - nlpaug==1.1.11
      - nltk==3.8.1
      - numba==0.61.2
      - numpy==1.26.4
      - nvidia-cublas-cu12==12.4.5.8
      - nvidia-cuda-cupti-cu12==12.4.127
      - nvidia-cuda-nvrtc-cu12==12.4.127
      - nvidia-cuda-runtime-cu12==12.4.127
      - nvidia-cudnn-cu12==9.1.0.70
      - nvidia-cufft-cu12==11.2.1.3
      - nvidia-curand-cu12==10.3.5.147
      - nvidia-cusolver-cu12==11.6.1.9
      - nvidia-cusparse-cu12==12.3.1.170
      - nvidia-cusparselt-cu12==0.6.2
      - nvidia-ml-py3==7.352.0
      - nvidia-nccl-cu12==2.21.5
      - nvidia-nvjitlink-cu12==12.4.127
      - nvidia-nvtx-cu12==12.4.127
      - omegaconf==2.2.3
      - opencensus==0.11.4
      - opencensus-context==0.1.3
      - opendatalab==0.0.10
      - openmim==0.3.9
      - openpyxl==3.1.5
      - openxlab==0.0.11
      - optuna==4.3.0
      - ordered-set==4.1.0
      - orjson==3.10.16
      - packaging==24.2
      - pandas==2.2.3
      - patsy==1.0.1
      - pdf2image==1.17.0
      - pillow==11.2.1
      - pip==25.0.1
      - platformdirs==4.3.7
      - plotly==6.0.1
      - preshed==3.0.9
      - prometheus-client==0.21.1
      - propcache==0.3.1
      - proto-plus==1.26.1
      - protobuf==6.30.2
      - psutil==6.1.1
      - py-spy==0.4.0
      - py4j==0.10.9.9
      - pyarrow==19.0.1
      - pyasn1==0.6.1
      - pyasn1-modules==0.4.2
      - pycryptodome==3.22.0
      - pydantic==2.11.3
      - pydantic-core==2.33.1
      - pygments==2.19.1
      - pyparsing==3.2.3
      - pysocks==1.7.1
      - pytesseract==0.3.10
      - python-dateutil==2.9.0.post0
      - pytorch-lightning==2.5.1
      - pytorch-metric-learning==2.3.0
      - pytz==2025.2
      - pyyaml==6.0.2
      - ray==2.39.0
      - referencing==0.36.2
      - regex==2024.11.6
      - requests==2.32.3
      - rich==14.0.0
      - rpds-py==0.24.0
      - rsa==4.9.1
      - s3transfer==0.11.5
      - safetensors==0.5.3
      - scikit-image==0.24.0
      - scikit-learn==1.5.2
      - scipy==1.15.2
      - sentencepiece==0.2.0
      - seqeval==1.2.2
      - setuptools==78.1.0
      - shellingham==1.5.4
      - six==1.17.0
      - smart-open==7.1.0
      - soupsieve==2.6
      - spacy==3.7.5
      - spacy-legacy==3.0.12
      - spacy-loggers==1.0.5
      - sqlalchemy==2.0.40
      - srsly==2.5.1
      - statsforecast==1.7.8
      - statsmodels==0.14.4
      - sympy==1.13.1
      - tabulate==0.9.0
      - tensorboard==2.19.0
      - tensorboard-data-server==0.7.2
      - tensorboardx==2.6.2.2
      - text-unidecode==1.3
      - textual==3.1.0
      - thinc==8.2.5
      - threadpoolctl==3.6.0
      - tifffile==2025.3.30
      - timm==1.0.3
      - tokenizers==0.21.1
      - toolz==0.12.1
      - torch==2.5.1
      - torchmetrics==1.2.1
      - torchvision==0.20.1
      - tqdm==4.67.1
      - transformers==4.51.3
      - triad==0.9.8
      - triton==3.1.0
      - typer==0.15.2
      - typing-extensions==4.13.2
      - typing-inspection==0.4.0
      - tzdata==2025.2
      - uc-micro-py==1.0.3
      - urllib3==2.4.0
      - utilsforecast==0.2.4
      - virtualenv==20.30.0
      - wasabi==1.1.3
      - weasel==0.4.1
      - werkzeug==3.1.3
      - window-ops==0.0.15
      - wrapt==1.17.2
      - xgboost==2.1.4
      - xxhash==3.5.0
      - yarl==1.20.0

# train and inference 
To train a light model and get the prediction without Bayesian optimization, unzip the file "dataset.zip" and run "totaldataset_optimal_angle_finder.py" with the dataset file put under the right file path.
To train a model with the complete autogluon structure, run "totaldataset_optimal_angle_finder_auto.py" instead.
